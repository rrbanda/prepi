= The LLM Handbook
:description: A Complete Guide to Understanding Large Language Models — From Concepts to Production
:keywords: LLM, large language models, transformers, attention, OpenShift AI, vLLM, KServe

*A Complete Guide to Understanding Large Language Models — From Concepts to Production*

== About This Book

This handbook takes you from zero knowledge to complete understanding of how Large Language Models work. Whether you're building AI products, deploying models to production, or simply curious about the technology behind ChatGPT, this guide will give you the mental models you need.

[NOTE]
====
*Practical OpenShift AI Content* — Key chapters include "In Practice" sections showing how LLM concepts apply in *Red Hat OpenShift AI*, with hands-on examples for training workbenches, model serving with vLLM/KServe, and production deployment using GitOps.
====

No prior machine learning knowledge required. Just curiosity.

== Who This Book Is For

* *Engineers* who use LLMs but want to understand them deeply
* *MLOps practitioners* deploying models to production
* *Product managers* working with AI teams
* *Curious minds* who want to know how the magic works

== How to Read This Book

This book is designed to be read sequentially. Each chapter builds on the previous ones. However, if you're already familiar with certain concepts, here's a guide:

[cols="1,1", options="header"]
|===
|If you know...
|Skip to...

|What LLMs do
|xref:03-tokenization.adoc[Chapter 3 (Tokenization)]

|Tokenization & embeddings
|xref:05-neural-networks.adoc[Chapter 5 (Neural Networks)]

|Neural network basics
|xref:07-attention.adoc[Chapter 7 (Attention)]

|How transformers work
|xref:09-inference.adoc[Chapter 9 (Inference)]

|LLM fundamentals, want production
|xref:12-serving-systems.adoc[Chapter 12 (Serving Systems)]
|===

== Conventions Used

Throughout this book, you'll see:

* *Pause and Reflect* — Moments to think before continuing
* *Chapter Takeaway* — The key insight from each chapter, boxed for easy review
* *In Practice with OpenShift AI* — How concepts apply in production using Red Hat OpenShift AI
* *Interactive Moments* — Questions to test your understanding
* Code blocks with concrete examples
* YAML examples for Kubernetes/OpenShift deployments
* Analogies to ground abstract concepts

_Let's begin with xref:00-prologue.adoc[the prologue]._
